{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_MULTIPROCESSING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import sys\n",
    "\n",
    "if os.path.isdir(\"__pycache__\"):\n",
    "    shutil.rmtree(\"__pycache__\")\n",
    "\n",
    "from modules.balance_dataset import input_output\n",
    "from modules.evaluation import fitness\n",
    "from modules.utils import results_folder\n",
    "from modules import visualize\n",
    "\n",
    "from modules import operator_set\n",
    "import operator\n",
    "\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import gp\n",
    "from deap import tools\n",
    "\n",
    "from modules.statistics import runtime_metrics\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "if USE_MULTIPROCESSING:\n",
    "    import multiprocessing as mp\n",
    "    from multiprocessing import Pool\n",
    "    import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '|'):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = 'modules/data/500ms'\n",
    "FILE_LIST = ['wav_ex1_spindles.csv','wav_ex2_spindles.csv','wav_ex3_spindles.csv','wav_ex4_spindles.csv','wav_ex5_spindles.csv','wav_ex6_spindles.csv','wav_ex7_spindles.csv','wav_ex8_spindles.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_output.read_dataset_list(DATASET_FOLDER, FILE_LIST)\n",
    "X_train, y_train, X_test, y_test = input_output.balance_dataset(data, data_columns = list(range(0,75)), label_column = 75, test_size = .2)\n",
    "\n",
    "# One hot vector\n",
    "# y_train = np.array([[x, int(not x)] for x in y_train])\n",
    "# y_test  = np.array([[x, int(not x)] for x in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance before feature construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier as MLP\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "classifier1 = KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier2 = MLP(hidden_layer_sizes = (15, ), activation = 'relu', max_iter = 200)\n",
    "classifier3 = SVC(kernel = 'rbf', probability=True)\n",
    "classifier4 = DT()\n",
    "classifier5 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.4912\n",
      "Recall   :  1.0\n",
      "F1-Score :  0.6588\n",
      "Accuracy :  0.4912\n",
      "AUC      :  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "classifier = classifier3\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_true = y_test\n",
    "predict_proba = classifier.predict_proba(X_test)\n",
    "\n",
    "y_true  = np.array([[x, int(not x)] for x in y_true])\n",
    "AUC = roc_auc_score(y_true, predict_proba)\n",
    "\n",
    "if AUC < 0.5:\n",
    "    AUC = 1 - AUC\n",
    "\n",
    "y_true = [i[0] for i in y_true]\n",
    "\n",
    "prf = precision_recall_fscore_support(y_true, y_pred)\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# y_pred = [i[0] for i in y_pred]\n",
    "        \n",
    "cfm = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "print('Precision: ', round(prf[0][0], 4))\n",
    "print('Recall   : ', round(prf[1][0], 4))\n",
    "print('F1-Score : ', round(prf[2][0], 4))\n",
    "print('Accuracy : ', round(acc, 4))\n",
    "print('AUC      : ', round(AUC, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_vars = ['auc']\n",
    "eval_func = fitness.eval_function(opt_vars)\n",
    "# Result: eval_func -> auc = lambda(y_true, y_pred)\n",
    "\n",
    "# eval_func = fitness.eval_function(['auc', 'acc'])\n",
    "## Result: eval_func -> auc, acc = lambda(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of inputs\n",
    "n_att = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    options:\n",
    "        nb: Naive Bayes; params: None\n",
    "        dt: Decision Tree; params: None\n",
    "        mlp: Multilayer Perceptron; params: [first hidden layer size,activation function]\n",
    "        knn: K Nearest Neighbors; params: [K,-1]\n",
    "        svm: Support Vector Machine; params: [-1,kernel]\n",
    "        kmeans: K-means Clustering (Using each cluster as a class of the problem); params: [number of clusters, -1]\n",
    "        external: Default = False. You can use any classifier, but the following methods (like scikit-learn):\n",
    "            fit(X, y)\n",
    "            predict(X)\n",
    "            predict_proba(X)\n",
    "\n",
    "    Example 1:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = 'rf'\n",
    "    external = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "    \n",
    "    Example 2:\n",
    "    classifier = 'nb'\n",
    "    external = False\n",
    "    \n",
    "    Example 3:\n",
    "    classifier = 'svm'\n",
    "    clf_param = [[], ['rbf']]\n",
    "    external = False\n",
    "'''\n",
    "classifier = 'nb'\n",
    "external = False\n",
    "clf_param = [[],[]] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GP operator set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pset = gp.PrimitiveSet(\"MAIN\", n_att)\n",
    "pset.addPrimitive(operator.add, 2)\n",
    "pset.addPrimitive(operator.sub, 2)\n",
    "pset.addPrimitive(operator.mul, 2)\n",
    "pset.addPrimitive(operator_set.plog, 1)\n",
    "pset.addPrimitive(operator_set.psqrt, 1)\n",
    "pset.addPrimitive(operator_set.pdiv, 2)\n",
    "pset.addPrimitive(operator_set.F, 1)\n",
    "# pset.addPrimitive(math.sin, 1)\n",
    "# pset.addPrimitive(math.cos, 1)\n",
    "# pset.addPrimitive(operator.neg, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GP parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Multiparameter optimization\n",
    "    opt_vars -> evaluation metrics\n",
    "    wts_vars -> tuple with each metric weight\n",
    "    \n",
    "    Example: Optimizing False positives and True positives\n",
    "    opt_vars = [FP, TP]\n",
    "    wts_vars = tuple([-1, 2])\n",
    "    \n",
    "    It means that we want to reduce False positives and maximize True positives. And it is more \n",
    "    important to have True positives, because we have set its weight higher.\n",
    "'''\n",
    "wts_vars = tuple([1])\n",
    "\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights = wts_vars)\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMulti)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "# Individual and population\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=3)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
    "\n",
    "# Evaluation method\n",
    "toolbox.register(\"evaluate\", fitness.eval_tree, clf = classifier, X_train = X_train, y_train = y_train, X_test = X_test, y_true = y_test, pset = pset, opt_vars = opt_vars, eval_func = eval_func, param = clf_param, external = external)\n",
    "\n",
    "# Initialization\n",
    "# toolbox.register(\"expr_init\", gp.genFull, min_=4, max_=7)\n",
    "# toolbox.register(\"expr_init\", gp.genGrow, min_=4, max_=7)\n",
    "toolbox.register(\"expr_init\", gp.genHalfAndHalf, min_=4, max_=7)\n",
    "\n",
    "# Selection\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "# toolbox.register(\"select\", tools.selRoulette)\n",
    "# toolbox.register(\"select\", tools.selRandom)\n",
    "\n",
    "# Crossover\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "# toolbox.register(\"mate\", gp.cxTwoPoint)\n",
    "# toolbox.register(\"mate\", gp.cxcxOnePointLeafBiased, termpb =.1)\n",
    "\n",
    "# Mutation\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_init, pset=pset)\n",
    "# toolbox.register(\"mutate\", gp.mutNodeReplacement, pset=pset)\n",
    "# toolbox.register(\"mutate\", gp.mutInsert, pset=pset)\n",
    "# toolbox.register(\"mutate\", gp.mutShrink)toolbox.register(\"mutate\", gp.mutEphemeral, mode = 'all')\n",
    "\n",
    "# Bloat Control\n",
    "TAM_MAX = 10\n",
    "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value = TAM_MAX))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value = TAM_MAX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.seed(1)\n",
    "start = time.time()\n",
    "mstats = runtime_metrics.init_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GP start: Population 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population size\n",
    "NPOP = 10\n",
    "\n",
    "# Execution number (identifier)\n",
    "NEXEC = 1\n",
    "\n",
    "# Number of generations\n",
    "NGEN = 10\n",
    "\n",
    "# Crossover probability\n",
    "CXPB = .85\n",
    "\n",
    "# Mutation probability\n",
    "MUTPB = .15\n",
    "pop = toolbox.population(NPOP)\n",
    "\n",
    "# Much faster!\n",
    "if USE_MULTIPROCESSING:\n",
    "    def ff(ind):\n",
    "        fit = fitness.eval_tree(ind, clf = classifier, X_train = X_train, y_train = y_train, X_test = X_test, y_true = y_test, pset = pset, opt_vars = opt_vars, eval_func = eval_func, param = clf_param, external = external)\n",
    "        if (math.isnan(fit[0])):\n",
    "            ind.fitness.values = 0,\n",
    "        else:\n",
    "            ind.fitness.values = fit\n",
    "        return ind\n",
    "\n",
    "    def fmate(children):\n",
    "        if random.random() < CXPB:\n",
    "            children = toolbox.mate(children[0], children[1])\n",
    "            del children[0].fitness.values\n",
    "            del children[1].fitness.values\n",
    "        return children[0], children[1]\n",
    "    \n",
    "    def fmutate(mutant):\n",
    "        if random.random() < MUTPB:\n",
    "            mutant = toolbox.mutate(mutant)[0]\n",
    "            del mutant.fitness.values\n",
    "        return mutant\n",
    "    \n",
    "    # t1 = time.time()\n",
    "    p = Pool(psutil.cpu_count()*2)\n",
    "    pop = p.map(ff, pop)\n",
    "    # t2 = time.time()\n",
    "      \n",
    "else:\n",
    "    # t3 = time.time()\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    \n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        if (math.isnan(fit[0])):\n",
    "            ind.fitness.values = 0,\n",
    "        else:\n",
    "            ind.fitness.values = fit\n",
    "    # t4 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = tools.Logbook()\n",
    "hof = tools.selBest(pop, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GP start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> (Exec 1) GP + nb - Feature Selection and Construction\n",
      ">> NGEN = 10 | NPOP = 10 | MAX_DEPTH = 10 | PARAM = [[], []]\n",
      ">> Optimizing: ['auc']\n",
      ">> Weights:    (1,)\n",
      ">> Progress: |||||||||||||||||||||||||||||||||||||||||||||||||||| 100.0% Complete\n",
      "-\n",
      ">> End (1 seconds)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toolbar_width = 50\n",
    "if NGEN < 50:\n",
    "    toolbar_width = NGEN\n",
    "\n",
    "# Verbosity level\n",
    "verb = 1\n",
    "if verb >= 1:\n",
    "    print(\">> (Exec \" + str(NEXEC) + \") GP + \" + classifier + \" - Feature Selection and Construction\")\n",
    "    print(\">> NGEN = \" + str(NGEN) + \" | NPOP = \" + str(NPOP) + \" | MAX_DEPTH = \" + str(TAM_MAX) + \" | PARAM = \" + str(clf_param))\n",
    "    print(\">> Optimizing: \" + str(opt_vars))\n",
    "    print(\">> Weights:    \" + str(wts_vars))\n",
    "    # if verb == 1:\n",
    "    #    sys.stdout.write(\"[%s]\" % (\" \" * toolbar_width))\n",
    "    #    sys.stdout.flush()\n",
    "    #    sys.stdout.write(\"\\b\" * (toolbar_width+1))\n",
    "\n",
    "# Results folder\n",
    "path = 'result_GP_' + str(NEXEC) + '/'\n",
    "results_folder.verify_create_dir(path)\n",
    "\n",
    "filename = 'GP_'+ classifier + '_' + 'NEXEC'\n",
    "balance = 1\n",
    "\n",
    "if verb == 1:\n",
    "    printProgressBar(0, NGEN, prefix = '>> Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "for g in range(NGEN):\n",
    "    geninit = time.time()\n",
    "    \n",
    "    if verb == 1:\n",
    "        printProgressBar(g + 1, NGEN, prefix = '>> Progress:', suffix = 'Complete', length = 50)\n",
    "\n",
    "    pop = toolbox.select(pop, NPOP)\n",
    "\n",
    "    if USE_MULTIPROCESSING:\n",
    "        offspring = list(map(toolbox.clone, pop))\n",
    "        offspring = p.map(fmate, list(zip(offspring[::2], offspring[1::2])))\n",
    "        offspring = [xx for sub in offspring for xx in sub]\n",
    "        offspring = p.map(fmutate, offspring)\n",
    "        offspring = p.map(ff, offspring)\n",
    "    else:\n",
    "        offspring = algorithms.varAnd(pop, toolbox, CXPB, MUTPB)\n",
    "        fitnesses = list(map(toolbox.evaluate, offspring))\n",
    "\n",
    "        for ind, fit in zip(offspring, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "            if (math.isnan(fit[0])):\n",
    "                ind.fitness.values = 0,\n",
    "            else:\n",
    "                ind.fitness.values = fit\n",
    "\n",
    "    hof = tools.selBest(pop, 1)\n",
    "\n",
    "    pop[:] = offspring + hof\n",
    "    log.record(gen = g, time = time.time() - geninit,**mstats.compile(pop))\n",
    "\n",
    "    if verb == 1:\n",
    "        if(g%int(NGEN/toolbar_width) == 0):\n",
    "            sys.stdout.write(\"-\")\n",
    "            sys.stdout.flush()\n",
    "    elif verb == 2:\n",
    "        print(log.stream)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "total_time = end - start\n",
    "\n",
    "if verb >= 1:\n",
    "    if total_time < 60:\n",
    "        print(\"\\n>> End (\" + str(round(total_time)) + \" seconds)\\n\")\n",
    "    elif total_time < 3600:\n",
    "        print(\"\\n>> End (\" + str(round(total_time/60)) + \" minutes)\\n\")\n",
    "    else:\n",
    "        print(\"\\n>> End (\" + str(math.floor(total_time/3600)) + \" hours and \" + str(round(abs(math.floor(total_time/3600)-total_time/3600)*60)) + \" minutes)\\n\")\n",
    "\n",
    "logfile = open(path + \"log/LOG_\" + filename + \"_\" + str(NEXEC) + \".csv\", 'w')\n",
    "logfile.write(str(log))\n",
    "logfile.close()\n",
    "\n",
    "prf, acc, cfm, AUC = fitness.performance(hof[0], classifier, X_train, y_train, X_test, y_test, pset, clf_param, external)\n",
    "\n",
    "info_file_name = os.path.join(path,\"infoGP.csv\")\n",
    "infoGP = open(info_file_name, 'a')\n",
    "if os.stat(info_file_name).st_size == 0:\n",
    "    infoGP.write(\"balance,DEEP MAX,classifier,P1,P2,#Exec,PPV_S,PPV_NS,TPR_S,TPR_NS,F1_S,F1_NS,SUP_S,SUP_NS,TN,FP,FN,TP,Acc,AUC,Deep,Training Time\\n\")\n",
    "\n",
    "infoGP.write(str(balance) + ',' + str(TAM_MAX) + ',' + classifier + ',' + str(clf_param[0]) + ',' + str(clf_param[1]) + ',' +  str(NEXEC) + ',' + str(prf[0][0]) + ',' \n",
    "        + str(prf[0][1]) + ',' + str(prf[1][0]) + ',' + str(prf[1][1]) + ',' + str(prf[2][0]) + ',' \n",
    "        + str(prf[2][1]) + ',' + str(prf[3][0]) + ',' + str(prf[3][1]) + ',' \n",
    "        + str(cfm[0]) + ',' + str(cfm[1]) + ',' + str(cfm[2]) + ',' + str(cfm[3]) + ',' \n",
    "        + str(acc) + ',' + str(AUC) + ',' + str(hof[0].height) + ',' + str(total_time) + '\\n')\n",
    "\n",
    "infoGP.close()\n",
    "\n",
    "tree = gp.PrimitiveTree(hof[0])\n",
    "expFILE = open(path + \"best_expr/EXPR_\" + filename + \"_\" +  str(NEXEC) + \".txt\", 'w')\n",
    "expFILE.write(str(tree))\n",
    "expFILE.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the best feature set created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ARG16]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(visualize.get_equations_simplified(hof[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6888\n",
      "Recall   :  0.7094\n",
      "F1-Score :  0.6989\n",
      "Accuracy :  0.6836\n",
      "AUC      :  0.762\n"
     ]
    }
   ],
   "source": [
    "prf, acc, cfm, AUC = fitness.performance(hof[0], classifier, X_train, y_train, X_test, y_test, pset, clf_param, external)\n",
    "print('Precision: ', round(prf[0][0], 4))\n",
    "print('Recall   : ', round(prf[1][0], 4))\n",
    "print('F1-Score : ', round(prf[2][0], 4))\n",
    "print('Accuracy : ', round(acc, 4))\n",
    "print('AUC      : ', round(AUC, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.68879668, 0.67772512]),\n",
       "  array([0.70940171, 0.6559633 ]),\n",
       "  array([0.69894737, 0.66666667]),\n",
       "  array([234, 218])),\n",
       " 0.6836283185840708,\n",
       " array([143,  75,  68, 166]),\n",
       " 0.7620363835960167)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness.performance(hof[0], 'nb', X_train, y_train, X_test, y_test, pset, external = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.62173913, 0.59009009]),\n",
       "  array([0.61111111, 0.60091743]),\n",
       "  array([0.61637931, 0.59545455]),\n",
       "  array([234, 218])),\n",
       " 0.6061946902654868,\n",
       " array([131,  87,  91, 143]),\n",
       " 0.6060142711518859)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness.performance(hof[0], 'dt', X_train, y_train, X_test, y_test, pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0.60743802, 0.58571429]),\n",
       "  array([0.62820513, 0.56422018]),\n",
       "  array([0.61764706, 0.57476636]),\n",
       "  array([234, 218])),\n",
       " 0.5973451327433629,\n",
       " array([123,  95,  87, 147]),\n",
       " 0.6553163961420843)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness.performance(hof[0], 'knn', X_train, y_train, X_test, y_test, pset, [5,''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([0.75      , 0.63602941]),\n",
       "  array([0.57692308, 0.79357798]),\n",
       "  array([0.65217391, 0.70612245]),\n",
       "  array([234, 218])),\n",
       " 0.6814159292035398,\n",
       " array([173,  45,  99, 135]),\n",
       " 0.7402767976162472)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness.performance(hof[0], 'mlp', X_train, y_train, X_test, y_test, pset, [15,'relu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((array([0.65909091, 0.68085106]),\n",
       "  array([0.74358974, 0.58715596]),\n",
       "  array([0.69879518, 0.63054187]),\n",
       "  array([234, 218])),\n",
       " 0.668141592920354,\n",
       " array([128,  90,  60, 174]),\n",
       " 0.7035599466792127)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness.performance(hof[0], 'svm', X_train, y_train, X_test, y_test, pset, ['','rbf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the GP tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/networkx-2.1-py3.5.egg/networkx/drawing/nx_pylab.py:611: MatplotlibDeprecationWarning: isinstance(..., numbers.Number)\n",
      "  if cb.is_numlike(alpha):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1152 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If the image appears wierd, please run this instruction again\n",
    "visualize.plot_tree(hof[0], path = path + \"best_expr/EXPR_\" + filename + \"_\" +  str(NEXEC) + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
